{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fatality Predictor - Notebook 2 - Modélisation et Évaluation des Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons entraîner et comparer plusieurs modèles de machine learning afin de prédire la gravité des accidents de la route. \"y\" représente la gravité d’un accident. Il vaut 0 si l'accident est mineur, 1 si il entraine au moins un blessé grave, sans mort, et 2 si l'accident est mortel.\n",
    "\n",
    "L’objectif ici est d’entraîner plusieurs modèles sur X_train seulement. Le dataset X_test ne sera utilisé qu’à la fin pour générer des prédictions y_pred_ des meilleurs modèles, qui seront comparées à y_test dans un dernier notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement, exploration et visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "from scipy.stats import mode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (76779, 36), y_train : (76779,)\n",
      "X_test  : (19195, 36)\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/sachaabitbol/Desktop/Projet Ramp SMS/\"\n",
    "\n",
    "df_train = pd.read_csv(path + \"X_train.csv\")  # Contient X_train et y_train\n",
    "df_test = pd.read_csv(path + \"X_test.csv\")\n",
    "\n",
    "y_train = df_train[\"y\"]\n",
    "X_train = df_train.drop(columns=[\"y\"])\n",
    "X_test = df_test.copy()\n",
    "\n",
    "print(f\"X_train : {X_train.shape}, y_train : {y_train.shape}\")\n",
    "print(f\"X_test  : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :\n",
      "\n",
      "   Numéro d'accident  Jour_semaine  Plein_jour  Nuit_éclairée  Obstacle  \\\n",
      "0       201800006621             4        True          False     False   \n",
      "1       201600001095             2       False          False     False   \n",
      "2       201700034431             1        True          False      True   \n",
      "3       201700024729             5        True          False     False   \n",
      "4       201700022470             2        True          False      True   \n",
      "\n",
      "   En_Agglomeration  Pluie  Pluie_Forte  Temps_Couvert  Plus_de_2_Vehicules  \\\n",
      "0             False  False        False          False                 True   \n",
      "1             False  False        False          False                False   \n",
      "2              True  False        False          False                False   \n",
      "3              True  False        False          False                False   \n",
      "4              True  False        False          False                 True   \n",
      "\n",
      "   ...  Nb_Choc_Avant  Nb_Choc_Arriere  Nb_Choc_Cote  Age_Min  Age_Max  \\\n",
      "0  ...              2                0             0     54.0     68.0   \n",
      "1  ...              1                0             0     31.0     31.0   \n",
      "2  ...              0                1             0     16.0     51.0   \n",
      "3  ...              1                1             1     24.0     24.0   \n",
      "4  ...              2                1             0     27.0     51.0   \n",
      "\n",
      "   Age_Moyen  Nb_Conducteurs  Nb_Passagers  Nb_Hommes  Nb_Femmes  \n",
      "0       59.3             3.0           0.0        2.0        1.0  \n",
      "1       31.0             1.0           0.0        1.0        0.0  \n",
      "2       33.5             2.0           0.0        2.0        0.0  \n",
      "3       24.0             1.0           0.0        1.0        0.0  \n",
      "4       37.3             3.0           0.0        0.0        3.0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train :\\n\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution de y_train :\n",
      "y\n",
      "0.0    0.594759\n",
      "1.0    0.349796\n",
      "2.0    0.055445\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution de y_train :\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids des classes : {0: 1.6813532876341508, 1: 2.8588091344669464, 2: 18.035891423933627}\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0: 1 / 0.594759, 1: 1 / 0.349796, 2: 1 / 0.055445}\n",
    "print(\"Poids des classes :\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entraînement et sélection des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des features booléennes et continues\n",
    "cols_bool = [col for col in X_train.columns if X_train[col].nunique() == 2]\n",
    "cols_continuous = [col for col in X_train.columns if col not in cols_bool]\n",
    "\n",
    "# Normalisation des features continues\n",
    "scaler = StandardScaler()\n",
    "X_train[cols_continuous] = scaler.fit_transform(X_train[cols_continuous])\n",
    "X_test[cols_continuous] = scaler.transform(X_test[cols_continuous])\n",
    "\n",
    "# Séparation en X_train_train et X_val pour validation\n",
    "X_train_train, X_val, y_train_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                              test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "# Définition des modèles et hyperparamètres\n",
    "\n",
    "models = {\n",
    "    \"Régression Logistique\": LogisticRegression(max_iter=500, class_weight=class_weights),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=class_weights),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"MLP (Neural Network)\": MLPClassifier(hidden_layer_sizes=(50,), max_iter=500),\n",
    "    \"SVM\": SVC(class_weight=class_weights),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight=class_weights),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(class_weight=class_weights),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\"Random Forest\": {\"n_estimators\": [100, 200, 500], \"max_depth\": [10, 20, None]},\n",
    "               \"Gradient Boosting\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1], \"max_depth\": [3, 5], \"subsample\" : [0.8]},\n",
    "               \"MLP (Neural Network)\": {\"hidden_layer_sizes\": [(50,), (100,), (50, 50)], \"activation\": [\"relu\", \"tanh\"], \"alpha\": [0.0001, 0.001]},\n",
    "               \"HistGradientBoosting\": {\"max_iter\": [100, 200, 300], \"learning_rate\": [0.01, 0.1, 0.2]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement de Régression Logistique...\n",
      "Entraînement de Random Forest...\n",
      "Entraînement de Gradient Boosting...\n",
      "Entraînement de MLP (Neural Network)...\n",
      "Entraînement de SVM...\n",
      "Entraînement de KNN...\n",
      "Entraînement de Decision Tree...\n",
      "Entraînement de Extra Trees...\n",
      "Entraînement de AdaBoost...\n",
      "Entraînement de HistGradientBoosting...\n",
      "\n",
      "Récapitulatif des performances sur X_val :\n",
      "HistGradientBoosting      : 0.7141\n",
      "Gradient Boosting         : 0.7030\n",
      "Random Forest             : 0.6909\n",
      "AdaBoost                  : 0.6896\n",
      "MLP (Neural Network)      : 0.6877\n",
      "Extra Trees               : 0.6683\n",
      "KNN                       : 0.6347\n",
      "Decision Tree             : 0.5964\n",
      "SVM                       : 0.5914\n",
      "Régression Logistique     : 0.5582\n",
      "\n",
      "Cinq meilleurs modèles : \n",
      "['HistGradientBoosting', 'Gradient Boosting', 'Random Forest', 'AdaBoost', 'MLP (Neural Network)']\n",
      "\n",
      "Optimisation de HistGradientBoosting avec GridSearchCV...\n",
      "Meilleur modèle trouvé pour HistGradientBoosting : {'learning_rate': 0.1, 'max_iter': 100}\n",
      "\n",
      "Optimisation de Gradient Boosting avec GridSearchCV...\n",
      "Meilleur modèle trouvé pour Gradient Boosting : {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Optimisation de Random Forest avec GridSearchCV...\n",
      "Meilleur modèle trouvé pour Random Forest : {'max_depth': None, 'n_estimators': 500}\n",
      "\n",
      "Optimisation de MLP (Neural Network) avec GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachaabitbol/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/sachaabitbol/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/sachaabitbol/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/sachaabitbol/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/sachaabitbol/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/sachaabitbol/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur modèle trouvé pour MLP (Neural Network) : {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50,)}\n"
     ]
    }
   ],
   "source": [
    "# Entraînement et évaluation des modèles\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    print(f\"Entraînement de {name}...\")\n",
    "    model.fit(X_train_train, y_train_train)\n",
    "    acc = accuracy_score(y_val, model.predict(X_val))\n",
    "    results[name] = acc\n",
    "\n",
    "print(\"\\nRécapitulatif des performances sur X_val :\")\n",
    "for name, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name.ljust(25)} : {acc:.4f}\")\n",
    "\n",
    "\n",
    "# Sélection des 5 meilleurs modèles\n",
    "best_models = sorted(results.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "best_models_names = [name for name, _ in best_models]\n",
    "print(\"\\nCinq meilleurs modèles : \")\n",
    "print(best_models_names)\n",
    "\n",
    "\n",
    "# Optimisation des hyperparamètres\n",
    "best_estimators = {}\n",
    "\n",
    "for model_name in best_models_names:\n",
    "    \n",
    "    model = models[model_name]\n",
    "\n",
    "    if model_name in param_grids:\n",
    "\n",
    "        print(f\"\\nOptimisation de {model_name} avec GridSearchCV...\")\n",
    "\n",
    "        param_grid = param_grids[model_name]\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "        grid_search.fit(X_train_train, y_train_train)\n",
    "\n",
    "        best_estimators[model_name] = grid_search.best_estimator_\n",
    "        print(f\"Meilleur modèle trouvé pour {model_name} : {grid_search.best_params_}\")\n",
    "\n",
    "    else:\n",
    "        best_estimators[model_name] = model.fit(X_train_train, y_train_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Génération des prédictions et Sauvegarde des résultats\n",
    "\n",
    "Nous avons maintenant sélectionné et optimisé nos 5 meilleurs modèles, à l’aide de GridSearchCV lorsque c’était nécessaire. Il est temps de générer leurs prédictions finales sur X_test, et de sauvegarder ces prédictions pour une évaluation future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération des prédictions sur X_test...\n",
      "\n",
      "  Prédiction avec HistGradientBoosting...\n",
      "  Prédiction avec Gradient Boosting...\n",
      "  Prédiction avec Random Forest...\n",
      "  Prédiction avec AdaBoost...\n",
      "  Prédiction avec MLP (Neural Network)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Génération des prédictions sur X_test...\\n\")\n",
    "y_preds = {}\n",
    "\n",
    "for model_name, model in best_estimators.items():\n",
    "    \n",
    "    print(f\"  Prédiction avec {model_name}...\")\n",
    "    y_preds[model_name] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame()\n",
    "\n",
    "for model_name, y_pred in y_preds.items():\n",
    "    y_pred_df[model_name] = y_pred\n",
    "\n",
    "# Génération de la prédiction par vote majoritaire\n",
    "y_pred_df[\"y_pred_vote\"] = mode(y_pred_df.values, axis=1)[0].flatten()\n",
    "\n",
    "# Sauvegarde du fichier contenant toutes les prédictions\n",
    "filename = f\"{path}y_pred.csv\"\n",
    "y_pred_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons entraîné et comparé plusieurs modèles de machine learning pour prédire la gravité des accidents de la route. Après une première phase de sélection des 5 meilleurs modèles, nous avons optimisé leurs hyperparamètres lorsque cela était nécessaire, puis généré des prédictions finales sur X_test. Nous avons également ajouté une prédiction par vote majoritaire entre ces modèles.\n",
    "\n",
    "Ces prédictions seront utilisées dans le Notebook 3, où nous comparerons les performances des modèles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
